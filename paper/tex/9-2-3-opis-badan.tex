\subsection{Opis odtworzenia badań }
Ze względu na niedostępność danych z\,platformy Facebook, musiało nastąpić kilka przekształceń w\,odtwarzaniu badań klasyfikacji nierzetelnych informacji na podstawie pracy Some Like It Hoax. Jednak mimo zmiany źródła pobierania danych logika pozostała niezmieniona. Na podstawie odkryć innych badań otrzymano listę kont należących do kilku kategorii. Sposób utworzenia listy danych opisano w\,podrozdziale \ref{wybor-danych}. Do tego badania ograniczono się do kategorii Junk odpowiadającej kategorii Hoax oraz kategorii Mainstream odpowiadającej kategorii Non-hoax. Dla odpowiednich kont na twitterze pobrano publikowane przez nie posty oraz informacje, o\,użytkownikach które ten post retweetowały czyli udostępniły na swoim koncie. 
\par
Aby jednak w\,dalszej części badań zachować jak największą spójność do odtworzenia wyników klasyfikacji dla obecnie analizowanych danych użyto udostępnionego kodu stworzonego przez twórców pracy Some Like It Hoax. 

\subsection{Opis użytych algorytmów }
Dokonano dwa podejścia do rozwiązania problemu klasyfikacji postów. Jako pierwsze potraktowano ten problem jako nadzorowaną klasyfikacje binarną używając regresji logistycznej. Następie przedstawiono ten problem jako problem binarnego etykietowania poprzez crowdsourcing (ang. boolean label crowdsourcing problem BLC). 
\subsubsection{Regresja logistyczna}
Przedstawiając powyższy problem jako nadzorowaną klasyfikację binarną klasyfikujemy przynależność postów I do odpowiedniej z\,dwóch klas – Junk albo Mainstream. Dzieje się to na podstawie ich cech, w\,tym przypadku cechami są użytkownicy U. Każdy post posiada zbiór cech, który może przyjmować jedną z\,dwóch możliwych wartości – 1, gdy dany użytkownik udostępnił dany post lub 0, gdy dany użytkownik nie udostępnił danego postu.
\par
Regresja logistyczna polega na wyuczeniu modelu poprzez znalezienie odpowiednich wag dla cech modelu.  W\,przedstawianym modelu są to wagi użytkowników $w_i$. W\,praktyce waga większa od zera oznacza, że użytkownik udostępnia w\,większości posty mainstreamowe a\,waga mniejsza od zera oznacza, że użytkownik udostępnia w\,większości posty należące do kategorii Junk. Na podstawie wyuczonych wag model oblicza prawdopodobieństwo $p_i$, że post należy do klasy mainstream.

\subsubsection{Binarne etykietowanie poprzez crowdsourcing}
Drugim podejściem jest przedstawienie problemu klasyfikacji postów jako problemu etykietowania poprzez crowdsourcing, czyli poprzez niepowiązane ze sobą osoby. Ten rodzaj problemów opisuje sytuacje w\,której duża grupa użytkowników oznacza dane etykietami prawda lub fałsz. Taka metoda może być używana do oznaczania czy edycja postu na Wikipedii jest aktem wandalizmu lub czy post lub strona jest odpowiednia dla dzieci\cite{de2015reliable}. W\,kontekście analizowanego zbioru postów na Twitterze uznano udostępnienie postu przez użytkownika jako oznaczenie go etykietą ‘prawda’.
\par
Badany problem różni się jednak nieznacznie od binarnego etykietowania poprzez crowdsourcing. Albowiem w\,BLC zakłada się, że użytkownicy dokonujący etykietowania są bardziej skłonni mówić prawdę. Algorytmy rozwiązujące ten problem porównują etykiety nadane przez użytkowników i\,naprostowują wyniki biorąc pod uwagę możliwość kłamstwa, aby uzyskać wyniki jakie etykiety powinny być posiadać obiekty.  Dlatego też nie jest tam używany zbiór uczący do dokonywania nadzoru.
\par
Natomiast w\,przypadku nadawania etykiet kategorii postom na Twitterze nie możemy zakładać, że użytkownicy będą preferowali udostępnianie postów mainstreamowych nad tymi z\,kategorii Junk. Co więcej, dzięki wcześniejszej analizie danych w\,rozdziale 8.5, wiemy że posty z\,obu kategorii mają porównywalną łączną liczbę udostępnień. Biorąc to więc pod uwagę należy posługiwać się zbiorem uczącym z\,określoną etykietą klasy.
\subsubsection{Algorytm harmoniczny}
Do podejścia przedstawiającego problem klasyfikacji postów jako problem BLC użyto algorytmu harmonicznego zaadaptowanego do tego zadania przez twórców pracy Some Like It Hoax. Algorytm ten opiera się na algorytmie przedstawionym dwa lata wcześniej\cite{de2015reliable} ale został dostosowany do dokonania klasyfikacji z\,zastosowaniem zbioru uczącego. 
\par
	Zbiór danych przedstawiony jest jako graf dwudzielny, gdzie wierzchołkami są posty oraz użytkownicy a\,łukami są zaznaczone udostępnienia postów przez użytkowników.  Bezpośrednie sąsiedztwo wierzchołków oznacza, że między postem a\,użytkownikiem nastąpiła interakcja.
\par
Traktując część postów jako zbiór uczący nadano im odpowiednie współczynniki, resztę pozostawiając nieokreśloną. Dzięki temu zabiegowi algorytm jest wstanie w\,pierwszym kroku obliczyć prawdopodobieństwo upodobań użytkowników, którzy te posty udostępnili. W\,praktyce oznacza to prawdopodobieństwo preferowania postów z\,kategorii Junk lub Mainstream. Aby uznać, że użytkownik jest spolaryzowany na daną kategorię musi posiadać on przewagę 2:1 udostępnień dla jednej z\,kategorii. 
\par
	Posiadając te informacje w\,kolejnych krokach zostają uaktualnione współczynniki postom które nie należą do zbioru uczącego a\,były udostępnione przez użytkowników o\,znanych już preferencjach. Następnie zostają uaktualnione preferencje użytkowników będących w\,bezpośrednim sąsiedztwie do postów posiadających etykiety. Dzięki kilkukrotnej iteracji tych kroków wiedza na temat postów oraz preferencji użytkowników zostaje rozpropagowana wewnątrz grafu. Taka możliwość transmisji informacji w\,grafie daje perspektywy na uzyskanie wysokich wyników precyzji klasyfikacji nawet z\,małego zbioru zaklasyfikowanych postów na początku algorytmu.
